{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Segmentation Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content:\n",
    " - what we are doing\n",
    " - where the data come from\n",
    " - what where the results there \n",
    " - what measures did they used\n",
    " - what measures do we use \n",
    " - what results do we use\n",
    " - what model do we use\n",
    " - how do we tune that model\n",
    " - what technology do we use (ternsorflow)\n",
    " - how much time does it take to segment a brain     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is in the Segmentation Project folder:\n",
    "- SISS2015 - a folder with medical images of 28 brains and their expert segmentations.\n",
    "- segm_model_1nn.py - model with 2 phase training (not using a cascade architecture)\n",
    "- predicted segmentations - a folder containing predicted segmentations of 28 brains, after running model_testing.py.\n",
    "- brain_data.py - module with helper functions\n",
    "- .chkp files - that's where our model is saved\n",
    "- valid_history - that's where  \n",
    "- the other files are not very important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The goal of the project\n",
    "The goal of the project is to perform an automatic Ischemic Stroke Lesion Segmentation of a brain.\n",
    "An automated method to locate the lesion area would support clinicians and researchers, rendering their findings more robust and reproducible. \n",
    "The data is taken from www.isles-challenge.org webpage, competition of 2015. We are interested in SISS sub-task, namely, in automatic segmentation of ischemic stroke lesion volumes from multi-spectral MRI sequences acquired in the sub-acute stroke development stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related works\n",
    "\n",
    "The best results in this task in the competition was achieved by Kamnitsas et.al. (Multi-Scale 3D Convolutional Neural Networks (CNNs) for Lesion Segmentation in Brain MRI) They used 3D CNNs. They achieved a dice coefficient of 0.64 before post-processing (0.66 after). In their paper Brain Tumor Segmentation with Deep Neural Networks, Havaei et.al. present a fully automatic brain tumor segmentation method based on CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "We use Convolutional Neural Networks in this project. The network is trained to predict whether the central voxel is pathology or normal brain tissue, depending on the content of the surrounding 2D horizontal patch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture\n",
    "We use architectures from Havaei et.al. paper for our problem.\n",
    "There are two main features of these architectures:\n",
    "1. They are two-path architectures. I.e., there are two branches in the architecture - local and global. The motivation for this architectural choice is that we would like our predictions to be made based on the local information around the voxel as well as on a global information, which could be thought of as information about the region of a brain where the voxel is located;\n",
    "2. The more advanced of them is a cascade architecture. It is unlikely that voxel labels are conditionally independent of the brain, and that's the assumption of out CNN model. Therefore we augment the architecture with another two-path CNN. This second CNN has the same architecture as the first one, the only difference is that we add extra input features which are the output from the first network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-phase training\n",
    "\n",
    "The training data is highly imbalanced, i.e., the healthy voxels comprise most of the brain.\n",
    "Therefore, as suggested in Havaei et. al. we employ a two-phase training strategy. We initially construct our patches data set such that both labels are equiprobable. This is what we call the first phase. In the second phase, we account for the unbalanced nature of the data and retrain the output layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation details\n",
    "We use TensorFlow library specialized in deep learning algorithms. It also supports the use of GPUs, which can greatly accelerate the execution of deep learning algorithms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
